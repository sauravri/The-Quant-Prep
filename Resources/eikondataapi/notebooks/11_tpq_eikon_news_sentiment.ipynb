{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://eikon.tpq.io/refinitiv_logo.png\" width=\"28%\" align=\"left\" style=\"vertical-align: top; padding-top: 23px;\">\n",
    "<img src=\"http://hilpisch.com/tpq_logo_long.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eikon Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment Scoring for News**\n",
    "\n",
    "Dr. Yves J. Hilpisch | The Python Quants GmbH\n",
    "\n",
    "<a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:training@tpq.io\">training@tpq.io</a>\n",
    "\n",
    "<img src=\"http://hilpisch.com/images/tr_eikon_02.png\" width=350px align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial covers **natural language processing (NLP)** based on news from the Eikon Data API:\n",
    "\n",
    "* Reading News Headlines\n",
    "* Extracting and Storing Raw Texts\n",
    "* Sentiment Scoring Examples\n",
    "* Sentiment Scoring Over Time\n",
    "* Combining Sentiment with Index Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following imports several **packages** as used in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # NumPy numerical computing\n",
    "import pandas as pd  # pandas Data Analysis\n",
    "import nltk, bs4  # NLP toolkit & BeautyfulSoup\n",
    "import eikon as ek  # the Eikon Python wrapper package\n",
    "import cufflinks as cf  # interactive plotting\n",
    "from bs4 import BeautifulSoup  # HTML parsing\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer  # sentiment analysis\n",
    "import configparser as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, download required files for `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following **Python and package versions** are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs4.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Eikon Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets the `app_id` to connect to the **Eikon Data API Proxy** which needs to be running locally. It requires the previously created text file `eikon.cfg` to be in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cp.ConfigParser()\n",
    "cfg.read('eikon.cfg')  # adjust for different file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.set_app_key(cfg['eikon']['app_id']) #set_app_id function being deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `ek.get_news_headlines()` allows you to search for and retrieve **news headlines**, including `storyId` values needed to retrieve the full news text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `query` string might contain `RICs` and other words to be searched for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = ek.get_news_headlines('R:.SPX \"TRUMP\" Language:LEN',\n",
    "                         date_from='2018-02-01',\n",
    "                         date_to='2018-05-28',\n",
    "                         count=100\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Raw Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analyses that follow are based on **all news stories** as identified above. To this end, the raw texts are collected in a `list` object (or loaded if such a file exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    news = pickle.load(open('eikon_news.pkl', 'rb'))\n",
    "except:\n",
    "    stories = []\n",
    "    for i, storyId in enumerate(news['storyId']):\n",
    "        try:\n",
    "            html = ek.get_news_story(storyId)\n",
    "            story = BeautifulSoup(html, 'html5lib').get_text()\n",
    "            stories.append(story)\n",
    "        except:\n",
    "            stories.append('')\n",
    "    news['story'] = stories\n",
    "    pickle.dump(news, open('eikon_news.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Scoring Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a `SentimentIntensityAnalyzer` object is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example illustrates a **negative sentiment** score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sid.polarity_scores(\n",
    "    '''This is absolute rubbish. I really didn't like. It was so bad.''')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one yields a **positive sentiment** score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sid.polarity_scores(\n",
    "    '''I really liked it. It was amazing. Real fun.''')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, a sentiment scoring can be implemented for a news text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = news.iloc[0]['story']\n",
    "text[200:350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sid.polarity_scores(text)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code scores all retrieved news texts for sentiments and collects the results in a `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for storyId in news['storyId']:\n",
    "    row = news[news['storyId'] == storyId]\n",
    "    scores = sid.polarity_scores(row['story'][0])\n",
    "    sentiment = sentiment.append(pd.DataFrame(scores, index=[row['versionCreated'][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.index = pd.DatetimeIndex(sentiment.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some statistics about the **sentiment scores** for all news texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **frequency distribution** for the compounded sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment['compound'].iplot(kind='histogram', bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compounded sentiment scores **over time** for raw values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment['compound'].iplot(mode='markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative compounded sentiment scores **over time** for raw values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment['compound'].cumsum().iplot(mode='markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative compounded sentiment scores **over time** with transformed values (to **`+1` and `-1`**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment['transform'] = sentiment['compound'].apply(lambda x: 1 if x > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment['transform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment['transform'].cumsum().iplot(mode='markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Sentiment with Index Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, retrieve **historical closing index levels** for the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ek.get_timeseries('.SPX',\n",
    "                         start_date='2018-02-01',\n",
    "                         end_date='2018-05-28',\n",
    "                         interval='daily',\n",
    "                         fields='CLOSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, **resample the cumulative compounded sentiment scores** to end-of-day and forward fill the empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = sentiment['compound'].cumsum().resample('D', label='right').last().ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, **join** the cumulative compounded sentiment scores with the historical index levels and **plot** the two time series (with different scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.join(daily).iplot(secondary_y='compound', width=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial covers the following **natural language processing (NLP)** tasks based on the Eikon Data API and respective Python packages:\n",
    "\n",
    "* Reading News Headlines\n",
    "* Extracting and Storing Raw Texts\n",
    "* Sentiment Scoring Examples\n",
    "* Sentiment Scoring Over Time\n",
    "* Combining Sentiment with Index Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eikon Data API Developer Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Overview](https://developers.thomsonreuters.com/eikon-data-apis) \n",
    "* [Quick Start ](https://developers.thomsonreuters.com/eikon-data-apis/quick-start)\n",
    "* [Documentation](https://developers.thomsonreuters.com/eikon-data-apis/docs)\n",
    "* [Downloads](https://developers.thomsonreuters.com/eikon-data-apis/downloads)\n",
    "* [Tutorials](https://developers.thomsonreuters.com/eikon-data-apis/learning)\n",
    "* [Q&A Forums](https://developers.thomsonreuters.com/eikon-data-apis/qa) \n",
    "\n",
    "Data Item Browser Application: Type `DIB` into Eikon Search Bar.\n",
    "\n",
    "* [Article on Chains](https://developers.thomsonreuters.com/article/simple-chain-objects-ema-part-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://eikon.tpq.io/refinitiv_logo.png\" width=\"28%\" align=\"left\" style=\"vertical-align: top; padding-top: 23px;\">\n",
    "<img src=\"http://hilpisch.com/tpq_logo_long.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
