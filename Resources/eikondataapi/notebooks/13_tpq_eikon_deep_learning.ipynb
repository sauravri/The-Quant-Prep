{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://eikon.tpq.io/refinitiv_logo.png\" width=\"28%\" align=\"left\" style=\"vertical-align: top; padding-top: 23px;\">\n",
    "<img src=\"http://hilpisch.com/tpq_logo_long.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eikon Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Financial Time Series Prediction &mdash; Using Deep Neural Networks**\n",
    "\n",
    "Dr. Yves J. Hilpisch | The Python Quants GmbH\n",
    "\n",
    "<a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:training@tpq.io\">training@tpq.io</a>\n",
    "\n",
    "<img src=\"http://hilpisch.com/images/tr_eikon_02.png\" width=350px align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows\n",
    "\n",
    "* how to retrieve historical intraday data across asset classes via the Eikon Data API,\n",
    "* how to work with such data using `pandas`, `Plotly` and `Cufflinks` and\n",
    "* how to apply deep learning techniques based on deep neural networks for time series prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eikon as ek  # the Eikon Python wrapper package\n",
    "import numpy as np  # NumPy\n",
    "import pandas as pd  # pandas\n",
    "import cufflinks as cf  # Cufflinks\n",
    "import tensorflow as tf  # Tensorflow\n",
    "import configparser as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following **Python and package versions** are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Eikon Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets the `app_id` to connect to the **Eikon Data API Proxy** which needs to be running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cp.ConfigParser()\n",
    "cfg.read('eikon.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.set_app_key(cfg['eikon']['app_id']) #set_app_id function being deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Intraday Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a **small universe of `RICS`** for which to retrieve data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rics = [\n",
    "    'SPY',  # S&P 500 ETF\n",
    "    'AAPL.O',  # Apple stock\n",
    "    'AMZN.O'  # Amazon stock\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, **intraday data** is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for ric in rics:\n",
    "    data[ric] = ek.get_timeseries(ric,  # the RICs\n",
    "                     fields='CLOSE',  # the required fields\n",
    "                     start_date='2018-05-02 12:00:00',  # start time\n",
    "                     end_date='2018-05-02 16:00:00', # end time\n",
    "                     interval='minute')['CLOSE']  # bar length  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()  # first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()  # final five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Log Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next calculate the **log returns** in vectorized fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.log(data / data.shift(1)).dropna()  # log returns in vectorized fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `Cufflinks`, we can plot the normalized financial time series as **line plots** for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalize().iplot(kind='lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequeny distributions, i.e. the **histograms**, of the log returns per `RIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.iplot(kind='histogram', subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Lagged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code that follows derives the **lagged data** for every single `RIC`. First, a function that adds columns with lagged data to a `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(data, ric, lags):\n",
    "    cols = []\n",
    "    df = pd.DataFrame(rets[ric])\n",
    "    for lag in range(1, lags + 1):\n",
    "        col = 'lag_{}'.format(lag)  # defines the column name\n",
    "        # creates the lagged data column with directional values\n",
    "        df[col] = df[ric].shift(lag)\n",
    "        cols.append(col)  # stores the column name\n",
    "    df.dropna(inplace=True)  # gets rid of incomplete data rows\n",
    "    return df, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the iterations over all `RICs`, using the `add_lags` function and storing the resulting `DataFrame` objects in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for ric in rics:\n",
    "    df, cols = add_lags(data, ric, lags)\n",
    "    dfs[ric] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols  # the column names for the lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()  # the keys of the dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['AAPL.O'].head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.digitize(dfs['AAPL.O'].head(7), bins=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** lags  # number of patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix consisting of the lagged data columns is used to \"predict\" the next day's direction of movement of the `RIC` via a **deep neural network (DNN)** algorithm. This is a **classification algorithm** that is able to **learn from historical patterns** (10 lags) to predict whether an upwards movement is more likely or a downwards movement.\n",
    "\n",
    "In what follows, the `Tensorflow` package from Google is used (see https://www.tensorflow.org/).\n",
    "\n",
    "<img src=\"http://hilpisch.com/images/tensorflow_logo.png\" width=\"15%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the definition of the **features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {col: tf.contrib.layers.real_valued_column(col, 1)\n",
    "      for col in cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values shall be **bucketized** later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = [tf.contrib.layers.bucketized_column(fd[col], boundaries=[0])\n",
    "     for col in cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model fitting, a Python function is required to deliver the **data for the features and labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    fc = {col: tf.constant(df[col]) for col in cols}\n",
    "    la = tf.constant(np.digitize(df[ric], bins=[0]))\n",
    "    return fc, la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the DNN can be trained (\"fitted\") to the data. The the **DNN model object** is instantiated with three hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ric in rics:\n",
    "    dnn = tf.contrib.learn.DNNClassifier(\n",
    "        hidden_units=[128, 128, 128],\n",
    "        feature_columns=fc)  # the DNN model\n",
    "    df = dfs[ric].copy()  # getting data for the RIC\n",
    "    dnn.fit(input_fn=get_data, steps=250)  # model fitting\n",
    "    # prediction step\n",
    "    dfs[ric]['position'] = list(dnn.predict(input_fn=get_data))\n",
    "    # transforming results to +1 and -1\n",
    "    dfs[ric]['position'] = np.where(dfs[ric]['position'] > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction value is either `+1` for an upwards movement or `-1` for a downwards movement. With regard to a using this as signals for a trading strategy, one **would go long for `+1` and go short for `-1`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    print('{:10} | {}'.format(ric, dfs[ric]['position'].values[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's backtest the performance of the DNN-based trading strategies. Here, vectorization is used for convencience and speed. First, the **strategy returns** which result from multiplying the prediction or position values by the log returns of the respective `RIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    dfs[ric]['strategy'] = dfs[ric]['position'] * dfs[ric][ric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the visualization of the **cumulative performance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    dfs[ric][[ric, 'strategy']].cumsum().apply(np.exp).iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to get a more realistic picture of the real trading performance to be expected a **train test split** to implement **out-of-sample backtesting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vspan = [{'x0': data.index[0], 'x1': data.index[split], 'color': 'green', 'fill': True, 'opacity': .2},\n",
    "        {'x0': data.index[split], 'x1': data.index[-1], 'color': 'red', 'fill': True, 'opacity': .2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly speaking, the **green part is taken for training**, the **red part for testing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalize().iplot(vspan=vspan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res = {}\n",
    "for ric in rics:\n",
    "    dnn = tf.contrib.learn.DNNClassifier(\n",
    "        hidden_units=[128, 128, 128],\n",
    "        feature_columns=fc)  # the DNN model\n",
    "    dfr = dfs[ric].copy()  # getting data for the RIC\n",
    "    # training step\n",
    "    df = dfr.iloc[:split]\n",
    "    dnn.fit(input_fn=get_data, steps=250)  # model fitting\n",
    "    # prediction step\n",
    "    df = dfr.iloc[split:]\n",
    "    pred = list(dnn.predict(input_fn=get_data))\n",
    "    # transforming results to +1 and -1\n",
    "    pred = np.where(np.array(pred) > 0, 1, -1)\n",
    "    # collecting the results\n",
    "    strat = pred * df[ric]\n",
    "    res[ric] = pd.DataFrame({ric: df[ric],\n",
    "                             'pred': pred,\n",
    "                             'strategy': strat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['AAPL.O'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    res[ric][[ric, 'strategy']].cumsum().apply(np.exp).iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this tutorial, we can conclude that\n",
    "\n",
    "* it is easy to retrieve **historical intraday data (one minute bars)** via the Eikon Data API,\n",
    "* `Plotly` and `Cufflinks` make **financial data visualization** convenient,\n",
    "* **deep learning (DL) techniques** such as **deep neural networks (DNN)** for classification are easily applied by the use of Python and\n",
    "* that such techniques might be helpful in **predicting the direction of market movements** using a lag- and pattern-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eikon Data API Developer Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Overview](https://developers.thomsonreuters.com/eikon-data-apis) \n",
    "* [Quick Start ](https://developers.thomsonreuters.com/eikon-data-apis/quick-start)\n",
    "* [Documentation](https://developers.thomsonreuters.com/eikon-data-apis/docs)\n",
    "* [Downloads](https://developers.thomsonreuters.com/eikon-data-apis/downloads)\n",
    "* [Tutorials](https://developers.thomsonreuters.com/eikon-data-apis/learning)\n",
    "* [Q&A Forums](https://developers.thomsonreuters.com/eikon-data-apis/qa) \n",
    "\n",
    "Data Item Browser Application: Type `DIB` into Eikon Search Bar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://eikon.tpq.io/refinitiv_logo.png\" width=\"28%\" align=\"left\" style=\"vertical-align: top; padding-top: 23px;\">\n",
    "<img src=\"http://hilpisch.com/tpq_logo_long.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
