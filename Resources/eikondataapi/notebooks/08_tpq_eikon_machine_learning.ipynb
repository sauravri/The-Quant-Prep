{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://eikon.tpq.io/refinitiv_logo.png\" width=\"28%\" align=\"left\" style=\"vertical-align: top; padding-top: 23px;\">\n",
    "<img src=\"http://hilpisch.com/tpq_logo_long.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eikon Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Financial Time Series Prediction &mdash; Recognizing Intraday Patterns**\n",
    "\n",
    "Dr. Yves J. Hilpisch | The Python Quants GmbH\n",
    "\n",
    "<a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:training@tpq.io\">training@tpq.io</a>\n",
    "\n",
    "<img src=\"http://hilpisch.com/images/tr_eikon_02.png\" width=350px align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows\n",
    "\n",
    "* how to retrieve historical intraday data across via the Eikon Data API,\n",
    "* how to work with such data using `pandas`, `Plotly` and `Cufflinks` and\n",
    "* how to apply machine learning (ML) techniques for time series prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eikon as ek  # the Eikon Python wrapper package\n",
    "import numpy as np  # NumPy\n",
    "import pandas as pd  # pandas\n",
    "import cufflinks as cf  # Cufflinks\n",
    "from sklearn.svm import SVC  # sckikit-learn\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import configparser as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following **Python and package versions** are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Eikon Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets the `app_id` to connect to the **Eikon Data API Proxy** which needs to be running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cp.ConfigParser()\n",
    "cfg.read('eikon.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.set_app_key(cfg['eikon']['app_id']) #set_app_id function being deprecated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Intraday Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a **small universe of `RICS`** for which to retrieve data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rics = [\n",
    "    'SPY',  # S&P 500 ETF\n",
    "    'AAPL.O',  # Apple stock\n",
    "    'AMZN.O'  # Amazon stock\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, **intraday data** is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for ric in rics:\n",
    "    data[ric] = ek.get_timeseries(ric,  # the RICs\n",
    "                     fields='CLOSE',  # the required fields\n",
    "                     start_date='2018-03-22 10:30:00',  # start date\n",
    "                     end_date='2018-03-22 16:00:00', # end date\n",
    "                     interval='minute')['CLOSE']  # bar length  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()  # first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()  # final five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Log Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next calculate the **log returns** in vectorized fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.log(data / data.shift(1)).dropna()  # log returns in vectorized fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While **financial time series data** in general is not stationary ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(data['AAPL.O'])  # test for stationarity of time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the **log returns time series data** is in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(rets['AAPL.O'])  # test for stationarity of time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `Cufflinks`, we can plot the normalized financial time series as **line plots** for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalize().iplot(kind='lines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequeny distributions, i.e. the **histograms**, of the log returns per `RIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.iplot(kind='histogram', subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Lagged Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create predictions for the financial time series analyzed, we work with **five lags**. The basic idea is that the historical (return) **values from the previous five days** are used to predict the value today. Consider the following simple data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "df = pd.DataFrame(np.arange(n), index=pd.date_range('2018-1-1', periods=n, freq='B'),\n",
    "                 columns=['data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates five additional columns with lagged data (one day back, two days back, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = 5\n",
    "for lag in range(1, lags + 1):\n",
    "    df['lag_{}'.format(lag)] = df['data'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code that follows derives the **lagged data** for every single `RIC`. First, a function that adds columns with lagged data to a `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(data, ric, lags):\n",
    "    cols = []\n",
    "    df = pd.DataFrame(rets[ric])\n",
    "    for lag in range(1, lags + 1):\n",
    "        col = 'lag_{}'.format(lag)  # defines the column name\n",
    "        # creates the lagged data column with directional values\n",
    "        df[col] = df[ric].shift(lag)\n",
    "        cols.append(col)  # stores the column name\n",
    "    df.dropna(inplace=True)  # gets rid of incomplete data rows\n",
    "    return df, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the iterations over all `RICs`, using the `add_lags` function and storing the resulting `DataFrame` objects in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for ric in rics:\n",
    "    df, cols = add_lags(data, ric, lags)\n",
    "    dfs[ric] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols  # the column names for the lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()  # the keys of the dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['AAPL.O'].head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sign(dfs['AAPL.O'].head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** lags  # number of patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ML Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix consisting of the lagged data columns is used to \"predict\" the next day's direction of movement of the `RIC` via the **support vector machine (SVM)** algorithm. This is a **classification algorithm** that is able to **learn from historical patterns** (5 lags) to predict whether an upwards movement is more likely or a downwards movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    model = SVC(C=100) # the ML model\n",
    "    df = dfs[ric].copy()  # getting data for the RIC\n",
    "    model.fit(np.sign(df[cols]), np.sign(df[ric]))  # model fitting\n",
    "    dfs[ric]['position'] = model.predict(np.sign(df[cols]))  # prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction value is either `+1` for an upwards movement or `-1` for a downwards movement. With regard to a using this as signals for a trading strategy, one **would go long for `+1` and go short for `-1`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    print('{:10} | {}'.format(ric, dfs[ric]['position'].values[:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's backtest the performance of the ML-based trading strategies. Here, vectorization is used for convencience and speed. First, the **strategy returns** which result from multiplying the prediction or position values by the log returns of the respective `RIC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    dfs[ric]['strategy'] = dfs[ric]['position'] * dfs[ric][ric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the visualization of the **cumulative performance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    dfs[ric][[ric, 'strategy']].cumsum().apply(np.exp).iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to get a more realistic picture of the real trading performance to be expected a **train test split** to implement **out-of-sample backtesting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vspan = [{'x0': data.index[0], 'x1': data.index[split], 'color': 'green', 'fill': True, 'opacity': .2},\n",
    "        {'x0': data.index[split], 'x1': data.index[-1], 'color': 'red', 'fill': True, 'opacity': .2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly speaking, the **green part is taken for training**, the **red part for testing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalize().iplot(vspan=vspan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for ric in rics:\n",
    "    model = SVC(C=100) # the ML model\n",
    "    df = dfs[ric].copy()  # getting data for the RIC\n",
    "    split = int(len(df) / 2)\n",
    "    train_x = np.sign(df[cols]).iloc[:split]\n",
    "    train_y = np.sign(df[ric]).iloc[:split]\n",
    "    test_x = np.sign(df[cols]).iloc[split:]\n",
    "    test_y = df[ric].iloc[split:]\n",
    "    model.fit(train_x, train_y)  # model fitting\n",
    "    pred = model.predict(test_x)  # prediction\n",
    "    strat = pred * test_y\n",
    "    res[ric] = pd.DataFrame({ric: test_y,\n",
    "                             'pred': pred,\n",
    "                             'strategy': strat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['AAPL.O'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ric in rics:\n",
    "    res[ric][[ric, 'strategy']].cumsum().apply(np.exp).iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this tutorial, we can conclude that\n",
    "\n",
    "* it is easy to retrieve **historical intraday data (one minute bars)** via the Eikon Data API,\n",
    "* `Plotly` and `Cufflinks` make **financial data visualization** convenient,\n",
    "* **machine learning (ML) techniques** such as SVM for classification are easily applied by the use of Python and\n",
    "* that such techniques might be helpful in **predicting the direction of market movements** using a lag and pattern-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eikon Data API Developer Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Overview](https://developers.thomsonreuters.com/eikon-data-apis) \n",
    "* [Quick Start ](https://developers.thomsonreuters.com/eikon-data-apis/quick-start)\n",
    "* [Documentation](https://developers.thomsonreuters.com/eikon-data-apis/docs)\n",
    "* [Downloads](https://developers.thomsonreuters.com/eikon-data-apis/downloads)\n",
    "* [Tutorials](https://developers.thomsonreuters.com/eikon-data-apis/learning)\n",
    "* [Q&A Forums](https://developers.thomsonreuters.com/eikon-data-apis/qa) \n",
    "\n",
    "Data Item Browser Application: Type `DIB` into Eikon Search Bar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://eikon.tpq.io/refinitiv_logo.png\" width=\"28%\" align=\"left\" style=\"vertical-align: top; padding-top: 23px;\">\n",
    "<img src=\"http://hilpisch.com/tpq_logo_long.png\" width=\"36%\" align=\"right\" style=\"vertical-align: top;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
